{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adding_sentiment_to_news.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXy3v1VpY2VD",
        "outputId": "3b3c7ace-526e-48c6-bf6d-8c28864775bd"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install torch\r\n",
        "!pip install pandas\r\n",
        "!pip install pathlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in c:\\program files\\python38\\lib\\site-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in c:\\program files\\python38\\lib\\site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in c:\\program files\\python38\\lib\\site-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in c:\\program files\\python38\\lib\\site-packages (from transformers) (2.25.0)\n",
            "Requirement already satisfied: numpy in c:\\program files\\python38\\lib\\site-packages (from transformers) (1.19.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\program files\\python38\\lib\\site-packages (from transformers) (2020.11.13)\n",
            "Requirement already satisfied: sacremoses in c:\\program files\\python38\\lib\\site-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\program files\\python38\\lib\\site-packages (from transformers) (4.51.0)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in c:\\program files\\python38\\lib\\site-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: protobuf in c:\\program files\\python38\\lib\\site-packages (from transformers) (3.13.0)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in c:\\program files\\python38\\lib\\site-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\program files\\python38\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in c:\\program files\\python38\\lib\\site-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python38\\lib\\site-packages (from requests->transformers) (1.26.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python38\\lib\\site-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\program files\\python38\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\program files\\python38\\lib\\site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in c:\\program files\\python38\\lib\\site-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in c:\\program files\\python38\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\bene\\appdata\\roaming\\python\\python38\\site-packages (from protobuf->transformers) (50.3.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch in c:\\program files\\python38\\lib\\site-packages (1.7.0+cu110)\n",
            "Requirement already satisfied: typing-extensions in c:\\program files\\python38\\lib\\site-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in c:\\program files\\python38\\lib\\site-packages (from torch) (0.6)\n",
            "Requirement already satisfied: numpy in c:\\program files\\python38\\lib\\site-packages (from torch) (1.19.3)\n",
            "Requirement already satisfied: future in c:\\program files\\python38\\lib\\site-packages (from torch) (0.18.2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in c:\\program files\\python38\\lib\\site-packages (1.1.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2020.4)\n",
            "Requirement already satisfied: numpy>=1.15.4 in c:\\program files\\python38\\lib\\site-packages (from pandas) (1.19.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\program files\\python38\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pathlib in c:\\program files\\python38\\lib\\site-packages (1.0.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in c:\\program files\\python38\\lib\\site-packages (1.19.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U4r4JnBZXyw"
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "from pathlib import Path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3jWxEbYbk4x",
        "outputId": "a9a2e4d1-6b2d-483b-d450-4a2adc97cd03"
      },
      "source": [
        "if torch.cuda.is_available():\r\n",
        "  print(\"\\nUsing: \", torch.cuda.get_device_name(0))\r\n",
        "  device = torch.device('cuda')\r\n",
        "else:\r\n",
        "  print(\"\\nUsing: CPU\")\r\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using:  GeForce GTX 1070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpkrUuL3ZdWX",
        "outputId": "7bc8edea-9fdd-4384-e18f-147f3856077e"
      },
      "source": [
        "#Load trained model\r\n",
        "model_dir = \"model\"\r\n",
        "model = BertForSequenceClassification.from_pretrained(model_dir, num_labels=3)\r\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\r\n",
        "model.to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrDDozfoZoPN"
      },
      "source": [
        "def load_dataset (data_filename):\r\n",
        "  data_path = Path(data_filename)\r\n",
        "  if data_path.exists():\r\n",
        "    print(f\"Loading {data_path}...\")\r\n",
        "    data_csv = pd.read_csv(data_path)\r\n",
        "    return data_csv\r\n",
        "  else:\r\n",
        "    print(f\"The dataset in {data_path} does not exist\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7JjpX0IZs-A",
        "outputId": "990ca8cb-ea4a-41f1-a85b-7cdd01cfc8a8"
      },
      "source": [
        "#Load dataset\r\n",
        "data = load_dataset(\"raw_partner_headlines.csv\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading raw_partner_headlines.csv...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsbBw4JAmvHI"
      },
      "source": [
        "def get_pred(sentence):\r\n",
        "  encoded_sentence = tokenizer.encode_plus(\r\n",
        "        sentence,                      # input the news headline\r\n",
        "        add_special_tokens = True,     # special tokens added to mark beginning & end of sentence\r\n",
        "        truncation = True,             # make all sentences a fixed length\r\n",
        "        padding = 'max_length',        # pad with zeros to max length\r\n",
        "        return_attention_mask = True,  # include attention mask in encoding\r\n",
        "        return_tensors = 'pt'          # return as pytorch tensor\r\n",
        "    )\r\n",
        "  input_ids = encoded_sentence['input_ids'].to(device)\r\n",
        "  attention_mask = encoded_sentence['attention_mask'].to(device)\r\n",
        "  out = model(input_ids, attention_mask)\r\n",
        "  pred = torch.argmax(out[0])\r\n",
        "  return pred.item()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLR4DDcjaV6P",
        "outputId": "166ef883-f472-45d8-cc7c-e8ab9897eeb1"
      },
      "source": [
        "sentiments = []\r\n",
        "for index, row in data.iterrows():\r\n",
        "  sentiments.append(get_pred(row['headline']))\r\n",
        "data['sentiment'] = sentiments\r\n",
        "print(data)\r\n",
        "data.to_csv(\"stock_sentiment_data.csv\", index=False, header = True, encoding='utf-8-sig')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Unnamed: 0                                           headline  \\\n",
            "0                 2  Agilent Technologies Announces Pricing of $5……...   \n",
            "1                 3  Agilent (A) Gears Up for Q2 Earnings: What's i...   \n",
            "2                 4  J.P. Morgan Asset Management Announces Liquida...   \n",
            "3                 5  Pershing Square Capital Management, L.P. Buys ...   \n",
            "4                 6  Agilent Awards Trilogy Sciences with a Golden ...   \n",
            "...             ...                                                ...   \n",
            "1845554     1849874                      Consumer Cyclical Sector Wrap   \n",
            "1845555     1849875                      Consumer Cyclical Sector Wrap   \n",
            "1845556     1849876  Zacks #5 Rank Additions for Monday - Tale of t...   \n",
            "1845557     1849877  4 Stock Strategies From Wall Street: Feb. 9 (U...   \n",
            "1845558     1849878        4 Stock Strategies From Wall Street: Feb. 9   \n",
            "\n",
            "                                                       url      publisher  \\\n",
            "0        http://www.gurufocus.com/news/1153187/agilent-...      GuruFocus   \n",
            "1        http://www.zacks.com/stock/news/931205/agilent...          Zacks   \n",
            "2        http://www.gurufocus.com/news/1138923/jp-morga...      GuruFocus   \n",
            "3        http://www.gurufocus.com/news/1138704/pershing...      GuruFocus   \n",
            "4        http://www.gurufocus.com/news/1134012/agilent-...      GuruFocus   \n",
            "...                                                    ...            ...   \n",
            "1845554  https://www.benzinga.com/content/12/08/2846030...      webmaster   \n",
            "1845555  https://www.benzinga.com/content/12/07/2767124...      webmaster   \n",
            "1845556  http://www.zacks.com/stock/news/73497/here-are...          Zacks   \n",
            "1845557  http://www.thestreet.com/story/11409053/1/4-st...  TheStreet.Com   \n",
            "1845558  https://www.benzinga.com/content/thestreet-com...      webmaster   \n",
            "\n",
            "                        date stock  sentiment  \n",
            "0        2020-06-01 00:00:00     A          2  \n",
            "1        2020-05-18 00:00:00     A          2  \n",
            "2        2020-05-15 00:00:00     A          1  \n",
            "3        2020-05-15 00:00:00     A          0  \n",
            "4        2020-05-12 00:00:00     A          0  \n",
            "...                      ...   ...        ...  \n",
            "1845554  2012-08-20 00:00:00    ZX          2  \n",
            "1845555  2012-07-23 00:00:00    ZX          2  \n",
            "1845556  2012-04-23 00:00:00    ZX          2  \n",
            "1845557  2012-02-09 00:00:00    ZX          2  \n",
            "1845558  2012-02-09 00:00:00    ZX          2  \n",
            "\n",
            "[1845559 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}